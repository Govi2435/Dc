"""
cnn_cifar10.py

A runnable example of a Convolutional Neural Network using Keras (TensorFlow backend).

- Dataset: CIFAR-10 (built-in)
- Framework: TensorFlow 2.x (tf.keras)
- Features: data normalization, simple model, callbacks (EarlyStopping, ModelCheckpoint),
  evaluation, and training history plots.

Run:
    python cnn_cifar10.py

Requirements:
    pip install tensorflow matplotlib numpy

Reference (uploaded): /mnt/data/MLDL experiment list.pdf
"""

import os
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt

# Reproducibility
SEED = 42
np.random.seed(SEED)
tf.random.set_seed(SEED)

def build_cnn(input_shape=(32, 32, 3), num_classes=10):
    """Builds a compact CNN suitable for CIFAR-10."""
    model = keras.Sequential([
        layers.Input(shape=input_shape),

        layers.Conv2D(32, (3,3), padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.Conv2D(32, (3,3), padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2,2)),
        layers.Dropout(0.25),

        layers.Conv2D(64, (3,3), padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.Conv2D(64, (3,3), padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2,2)),
        layers.Dropout(0.30),

        layers.Conv2D(128, (3,3), padding='same', activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2,2)),
        layers.Dropout(0.35),

        layers.Flatten(),
        layers.Dense(256, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.4),
        layers.Dense(num_classes, activation='softmax')
    ], name='simple_cnn_cifar10')
    return model

def preprocess_data():
    """Loads CIFAR-10 and preprocesses (normalize and one-hot labels)."""
    (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()
    # scale to [0,1]
    x_train = x_train.astype("float32") / 255.0
    x_test  = x_test.astype("float32")  / 255.0

    # subtract per-channel mean (optional but common)
    mean = np.mean(x_train, axis=(0,1,2), keepdims=True)
    std  = np.std(x_train, axis=(0,1,2), keepdims=True)
    x_train = (x_train - mean) / (std + 1e-7)
    x_test  = (x_test  - mean) / (std + 1e-7)

    # one-hot encode labels
    num_classes = 10
    y_train = keras.utils.to_categorical(y_train, num_classes)
    y_test  = keras.utils.to_categorical(y_test, num_classes)

    return (x_train, y_train), (x_test, y_test)

def plot_history(history, out_dir=None):
    """Plot loss and accuracy curves from Keras History object."""
    hist = history.history
    epochs = range(1, len(hist['loss']) + 1)

    plt.figure(figsize=(12,4))

    plt.subplot(1,2,1)
    plt.plot(epochs, hist['loss'], label='train loss')
    if 'val_loss' in hist:
        plt.plot(epochs, hist['val_loss'], label='val loss')
    plt.title('Loss')
    plt.xlabel('Epoch')
    plt.legend()

    plt.subplot(1,2,2)
    # determine accuracy key
    acc_key = 'accuracy' if 'accuracy' in hist else 'sparse_categorical_accuracy'
    plt.plot(epochs, hist[acc_key], label='train acc')
    if 'val_' + acc_key in hist:
        plt.plot(epochs, hist['val_' + acc_key], label='val acc')
    plt.title('Accuracy')
    plt.xlabel('Epoch')
    plt.legend()

    plt.tight_layout()
    if out_dir:
        os.makedirs(out_dir, exist_ok=True)
        path = os.path.join(out_dir, 'training_curves.png')
        plt.savefig(path)
        print(f"Saved training curves to: {path}")
    plt.show()

def main():
    # Hyperparameters
    batch_size = 128
    epochs = 30
    learning_rate = 1e-3
    model_dir = "saved_models"
    os.makedirs(model_dir, exist_ok=True)
    checkpoint_path = os.path.join(model_dir, "cnn_cifar10_best.h5")

    # Prepare data
    (x_train, y_train), (x_test, y_test) = preprocess_data()
    input_shape = x_train.shape[1:]
    num_classes = y_train.shape[1]

    # Build model
    model = build_cnn(input_shape=input_shape, num_classes=num_classes)
    model.summary()

    # Compile
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    # Callbacks
    callbacks = [
        keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_loss',
                                        save_best_only=True, verbose=1),
        keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),
        keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)
    ]

    # Option: simple data augmentation generator
    datagen = keras.preprocessing.image.ImageDataGenerator(
        width_shift_range=0.1,
        height_shift_range=0.1,
        horizontal_flip=True
    )
    datagen.fit(x_train)

    # Train (using generator)
    steps_per_epoch = int(np.ceil(x_train.shape[0] / batch_size))
    history = model.fit(
        datagen.flow(x_train, y_train, batch_size=batch_size),
        steps_per_epoch=steps_per_epoch,
        epochs=epochs,
        validation_data=(x_test, y_test),
        callbacks=callbacks,
        verbose=2
    )

    # Evaluate
    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)
    print(f"\nTest loss: {test_loss:.4f}  Test accuracy: {test_acc:.4f}")

    # Save final model
    final_model_path = os.path.join(model_dir, "cnn_cifar10_final.h5")
    model.save(final_model_path)
    print(f"Saved final model to: {final_model_path}")

    # Plot training curves
    plot_history(history, out_dir=model_dir)

    # Show a few predictions
    preds = model.predict(x_test[:10])
    pred_labels = np.argmax(preds, axis=1)
    true_labels = np.argmax(y_test[:10], axis=1)
    print("\nFirst 10 predictions (pred -> true):")
    for i in range(10):
        print(f"{pred_labels[i]} -> {true_labels[i]}")

if __name__ == "__main__":
    main()
