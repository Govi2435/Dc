"""
Example A: Simple dense neural network with Keras (TensorFlow backend)
Dataset: Iris (3 classes)
Requirements: tensorflow, scikit-learn, numpy
Run: python iris_keras.py   (or paste into a notebook cell)
"""

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import OneHotEncoder

# 1) Load & preprocess
data = load_iris()
X = data['data']            # shape (150, 4)
y = data['target'].reshape(-1, 1)  # shape (150, 1)

# One-hot encode labels
ohe = OneHotEncoder(sparse=False)
Y = ohe.fit_transform(y)    # shape (150, 3)

# Train/test split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)

# Feature scaling (important for neural networks)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# 2) Build model (a compact MLP)
def build_model(input_dim, num_classes):
    model = keras.Sequential([
        layers.Input(shape=(input_dim,)),
        layers.Dense(32, activation='relu'),
        layers.Dense(16, activation='relu'),
        layers.Dense(num_classes, activation='softmax')  # softmax for multi-class
    ])
    return model

model = build_model(input_dim=X_train.shape[1], num_classes=Y_train.shape[1])
model.summary()

# 3) Compile
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.01),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# 4) Train
history = model.fit(
    X_train, Y_train,
    validation_split=0.1,
    epochs=50,
    batch_size=8,
    verbose=2
)

# 5) Evaluate
loss, acc = model.evaluate(X_test, Y_test, verbose=0)
print(f"\nTest loss: {loss:.4f}  Test accuracy: {acc:.4f}")

# 6) Predict on new samples
sample = X_test[:5]
probs = model.predict(sample)
preds = probs.argmax(axis=1)
true_labels = Y_test.argmax(axis=1)
print("\nSample predictions (probabilities):")
for i, p in enumerate(probs):
    print(f"true: {true_labels[i]}  pred: {preds[i]}  probs: {np.round(p,3)}")
