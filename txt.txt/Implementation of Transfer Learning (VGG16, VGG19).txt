"""
transfer_vgg.py

Transfer learning examples with VGG16 and VGG19 using tf.keras.

Features:
 - Use either VGG16 or VGG19 (ImageNet weights)
 - Two modes: 'feature' (feature-extraction) and 'finetune' (unfreeze top layers)
 - Supports CIFAR-10 built-in dataset (default) or a directory of images (--data-dir)
 - Data augmentation, callbacks, model saving and evaluation

Requirements:
  pip install tensorflow numpy matplotlib

Run examples:
  python transfer_vgg.py --base vgg16 --mode feature --epochs 8
  python transfer_vgg.py --base vgg19 --mode finetune --data-dir /path/to/data --epochs 20
"""

import os
import argparse
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import applications
import matplotlib.pyplot as plt

# Reproducibility
SEED = 42
np.random.seed(SEED)
tf.random.set_seed(SEED)

def get_base_model(name='vgg16', input_shape=(224,224,3), weights='imagenet'):
    name = name.lower()
    if name == 'vgg16':
        base = applications.VGG16(weights=weights, include_top=False, input_shape=input_shape)
    elif name == 'vgg19':
        base = applications.VGG19(weights=weights, include_top=False, input_shape=input_shape)
    else:
        raise ValueError("Unsupported base model. Choose 'vgg16' or 'vgg19'.")
    return base

def build_transfer_model(base_name='vgg16', mode='feature', input_shape=(224,224,3), num_classes=10, dropout=0.5, finetune_at_layer=None):
    """
    mode: 'feature' -> freeze base; 'finetune' -> unfreeze top layers (controlled by finetune_at_layer)
    finetune_at_layer: index or None. If None and mode=='finetune', we unfreeze last conv block by heuristic.
    """
    base_model = get_base_model(base_name, input_shape=input_shape, weights='imagenet')

    # Decide which layers to freeze
    if mode == 'feature':
        base_model.trainable = False
    elif mode == 'finetune':
        # freeze all first, then unfreeze top layers
        base_model.trainable = True
        # We'll freeze all layers up to finetune_at_layer (if provided)
        if finetune_at_layer is None:
            # heuristic: unfreeze last convolutional block
            # for VGG16/VGG19, last conv block name contains 'block5'
            finetune_at_layer = 0
            for i, layer in enumerate(base_model.layers):
                if 'block5' in layer.name:
                    finetune_at_layer = i
                    break
        for i, layer in enumerate(base_model.layers):
            layer.trainable = (i >= finetune_at_layer)
    else:
        raise ValueError("mode must be 'feature' or 'finetune'")

    inputs = keras.Input(shape=input_shape)
    x = inputs
    # optional preprocessing (VGG expects inputs scaled to the ImageNet preprocessing)
    x = applications.vgg16.preprocess_input(x * 255.0)  # since data generator outputs [0,1]
    x = base_model(x, training=False)
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(512, activation='relu')(x)
    x = layers.Dropout(dropout)(x)
    outputs = layers.Dense(num_classes, activation='softmax')(x)

    model = keras.Model(inputs, outputs, name=f"{base_name}_{mode}")
    return model

def prepare_data_cifar(batch_size=32, img_size=(224,224)):
    """Load CIFAR-10, resize to img_size, normalize to [0,1], one-hot labels."""
    (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()
    # scale to [0,1]
    x_train = x_train.astype('float32') / 255.0
    x_test  = x_test.astype('float32') / 255.0

    # resize using tf.image
    def resize_images(images, size):
        images_resized = tf.image.resize(images, size, method='bilinear').numpy()
        return images_resized

    x_train = resize_images(x_train, img_size)
    x_test = resize_images(x_test, img_size)

    num_classes = 10
    y_train_cat = keras.utils.to_categorical(y_train, num_classes)
    y_test_cat  = keras.utils.to_categorical(y_test, num_classes)
    return (x_train, y_train_cat), (x_test, y_test_cat)

def prepare_data_from_dir(data_dir, img_size=(224,224), batch_size=32, subset_split=0.2, seed=SEED):
    """
    Expects directory structure:
      data_dir/
        train/ (optional) or class subfolders
        val/   (optional)
    If data_dir contains class subfolders directly, we use validation_split on the training generator.
    """
    # If user has 'train' and 'val' subdirs use flow_from_directory without split
    train_dir = os.path.join(data_dir, 'train')
    val_dir = os.path.join(data_dir, 'val')
    if os.path.isdir(train_dir) and os.path.isdir(val_dir):
        train_ds = keras.preprocessing.image.ImageDataGenerator(
            preprocessing_function=applications.vgg16.preprocess_input,
            rescale=None,
            horizontal_flip=True,
            width_shift_range=0.1,
            height_shift_range=0.1
        ).flow_from_directory(train_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical', seed=seed)
        val_ds = keras.preprocessing.image.ImageDataGenerator(
            preprocessing_function=applications.vgg16.preprocess_input,
            rescale=None
        ).flow_from_directory(val_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical', seed=seed, shuffle=False)
        return train_ds, val_ds
    else:
        # use validation_split on single directory with class subfolders
        datagen_train = keras.preprocessing.image.ImageDataGenerator(
            preprocessing_function=applications.vgg16.preprocess_input,
            rescale=None,
            horizontal_flip=True,
            width_shift_range=0.1,
            height_shift_range=0.1,
            validation_split=subset_split
        )
        train_ds = datagen_train.flow_from_directory(data_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical', subset='training', seed=seed)
        val_ds = datagen_train.flow_from_directory(data_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical', subset='validation', seed=seed)
        return train_ds, val_ds

def plot_history(history, out_dir=None):
    hist = history.history
    epochs = range(1, len(hist['loss']) + 1)
    plt.figure(figsize=(10,4))
    plt.subplot(1,2,1)
    plt.plot(epochs, hist['loss'], label='train loss')
    if 'val_loss' in hist:
        plt.plot(epochs, hist['val_loss'], label='val loss')
    plt.legend(); plt.title('Loss'); plt.xlabel('Epoch')

    plt.subplot(1,2,2)
    acc_key = 'accuracy' if 'accuracy' in hist else 'sparse_categorical_accuracy'
    plt.plot(epochs, hist[acc_key], label='train acc')
    if 'val_' + acc_key in hist:
        plt.plot(epochs, hist['val_' + acc_key], label='val acc')
    plt.legend(); plt.title('Accuracy'); plt.xlabel('Epoch')

    plt.tight_layout()
    if out_dir:
        os.makedirs(out_dir, exist_ok=True)
        plt.savefig(os.path.join(out_dir, 'training_history.png'))
        print("Saved training history to", os.path.join(out_dir, 'training_history.png'))
    plt.show()

def main(args):
    img_size = (224, 224)
    batch_size = args.batch_size
    epochs = args.epochs
    base_name = args.base.lower()
    mode = args.mode.lower()
    model_dir = args.model_dir
    os.makedirs(model_dir, exist_ok=True)

    # Data preparation
    if args.data_dir:
        print("Loading data from directory:", args.data_dir)
        train_ds, val_ds = prepare_data_from_dir(args.data_dir, img_size=img_size, batch_size=batch_size)
        steps_per_epoch = train_ds.samples // batch_size
        validation_steps = val_ds.samples // batch_size
        num_classes = train_ds.num_classes
        use_generator = True
    else:
        print("Using CIFAR-10 dataset (resized to 224x224)")
        (x_train, y_train), (x_test, y_test) = prepare_data_cifar(batch_size=batch_size, img_size=img_size)
        num_classes = y_train.shape[1]
        # build tf.data.Dataset for performance
        train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(1000, seed=SEED).batch(batch_size).prefetch(tf.data.AUTOTUNE)
        val_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size).prefetch(tf.data.AUTOTUNE)
        steps_per_epoch = int(np.ceil(x_train.shape[0] / batch_size))
        validation_steps = int(np.ceil(x_test.shape[0] / batch_size))
        use_generator = False

    # Build model
    model = build_transfer_model(base_name=base_name, mode=mode, input_shape=(img_size[0], img_size[1], 3), num_classes=num_classes, dropout=0.5)
    model.summary()

    # Compile: for fine-tuning use lower LR
    if mode == 'feature':
        lr = args.lr_feature
    else:
        lr = args.lr_finetune
    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),
                  loss='categorical_crossentropy', metrics=['accuracy'])

    # Callbacks
    checkpoint_path = os.path.join(model_dir, f"{base_name}_{mode}_best.h5")
    callbacks = [
        keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, verbose=1),
        keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),
        keras.callbacks.EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=1)
    ]

    # Train
    if use_generator:
        history = model.fit(
            train_ds,
            steps_per_epoch=steps_per_epoch,
            validation_data=val_ds,
            validation_steps=validation_steps,
            epochs=epochs,
            callbacks=callbacks,
            verbose=2
        )
    else:
        history = model.fit(
            train_ds,
            epochs=epochs,
            validation_data=val_ds,
            callbacks=callbacks,
            verbose=2
        )

    # Evaluate
    if use_generator:
        loss, acc = model.evaluate(val_ds, steps=validation_steps, verbose=2)
    else:
        loss, acc = model.evaluate(val_ds, verbose=2)
    print(f"\nValidation loss: {loss:.4f}  accuracy: {acc:.4f}")

    # Save final
    final_path = os.path.join(model_dir, f"{base_name}_{mode}_final.h5")
    model.save(final_path)
    print("Saved final model to:", final_path)

    # Plot history
    plot_history(history, out_dir=model_dir)

    # show some predictions on a small batch (only if not using dir generator)
    if not use_generator:
        sample_x, sample_y = next(iter(val_ds.take(1)))
        preds = model.predict(sample_x[:8])
        pred_labels = np.argmax(preds, axis=1)
        true_labels = np.argmax(sample_y[:8].numpy(), axis=1)
        print("\nSample predictions (pred -> true):")
        for p, t in zip(pred_labels, true_labels):
            print(f"{p} -> {t}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Transfer Learning with VGG16/VGG19 (feature-extraction & fine-tune)")
    parser.add_argument('--base', choices=['vgg16', 'vgg19'], default='vgg16', help='Base model to use')
    parser.add_argument('--mode', choices=['feature', 'finetune'], default='feature', help='Training mode')
    parser.add_argument('--data-dir', default=None, help='Path to data directory (optional). If omitted uses CIFAR-10 resized to 224x224.')
    parser.add_argument('--batch-size', type=int, default=32, help='Batch size')
    parser.add_argument('--epochs', type=int, default=12, help='Number of epochs')
    parser.add_argument('--model-dir', default='saved_models', help='Directory to save checkpoints and final model')
    parser.add_argument('--lr-feature', type=float, default=1e-3, help='Learning rate for feature-extraction phase')
    parser.add_argument('--lr-finetune', type=float, default=1e-4, help='Learning rate for fine-tuning phase (use smaller)')
    args = parser.parse_args()

    main(args)
